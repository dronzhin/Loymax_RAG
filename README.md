# Прототип сервиса вопрос-ответ (Q&A) на основе RAG архитектуры

## Задача

Разработать прототип сервиса вопрос-ответ (Q&A) на основе RAG архитектуры. Система должна:

- Принимать текстовый вопрос пользователя.
- Находить наиболее релевантные фрагменты информации из предоставленного набора документов (knowledge base).
- Использовать LLM для генерации полного, информативного ответа на основе найденных фрагментов.
- Быть реализована как набор взаимодействующих микросервисов/компонентов, готовых к контейнеризации и развертыванию.
- Иметь потенциал для горизонтального масштабирования.

## Данные

[Ссылка на данные](https://raw.githubusercontent.com/vladislavneon/RuBQ/refs/heads/master/RuBQ_2.0/RuBQ_2.0_paragraphs.json)

### Структура данных

- **uid**: уникальный идентификатор фрагмента.
- **ru_wiki_pageid**: ID страницы википедии.
- **text**: текстовый фрагмент о ЦСКА (история, матчи, игроки и т.д.). 

## Анализ данных

### Пропуски
- В данных нет пропусков. Все столбцы содержат **56,952** записи.

### Уникальные значения
- **uid**: 56,952 уникальных значения.
- **ru_wiki_pageid**: 9,105 уникальных значений.
- **text**: 56,826 уникальных текстовых записей.

### Минимальное и максимальное количество символов
- **text**: Минимальная длина текста составляет **1** символ, а максимальная — **11,010** символов.

#### Примеры записей с минимальным текстом

| uid    | text | text_length |
|--------|------|-------------|
| 43257  | Глаз | 4           |
| 43467  | Болт | 4           |
| 41914  | Синин| 5           |
| 11493  | Дакар| 5           |
| 44505  | Кронос| 6          |
| 47097  | Парана| 6          |
| 44877  | R.E.M.| 6          |
| 39789  | Церера| 6          |
| 14068  | Сурими| 6          |
| 19556  | Сезон 1| 7         |
| 46208  | Пётр I;| 7         |
| 19560  | Сезон 2| 7         |

#### Выводы

Анализ данных показал, что многие записи содержат слова или предложения, вырванные из контекста, что значительно снижает их информативность. Например, запись "Сезон 2" указывает на то, что последующие данные относятся именно к этому сезону. Для сохранения информативности имеет смысл объединить такие данные.

## Анализ данных после объединения по `ru_wiki_pageid`, очистки, разделения текста на оптимальную величину символов и удаления дубликатов

### Пропуски
- В данных отсутствуют пропуски. Все столбцы содержат **9,104** записи.

### Минимальная и максимальная длина текста
- **text**: 
  - Минимальная длина: **27** символов
  - Максимальная длина: **102,332** символов

### Минимальная и максимальная длина текста после разделения на равномерные части, каждая из которых не превышает 20,000 символов
- **text**:
  - содержат **9,214** записи
  - Минимальная длина: **27** символов
  - Максимальная длина: **19,584** символов

## Структура проекта

```plaintext
project/
│
├── data/
│   ├── data.json
│   ├── data.log
│   ├── faiss_index.bin
│   └── metadata.pkl
│
├── src/
│   ├── indexing_service/
│   │   ├── Dockerfile
│   │   ├── main.py
│   │   ├── analysis.py
│   │   ├── load_and_save.py
│   │   ├── processing.py
│   │   ├── vectorize.py
│   │   └── requirements.txt
│   │
│   ├── query_service/
│   │   ├── Dockerfile
│   │   ├── main.py
│   │   ├── query.py
│   │   └── requirements.txt
│   │
│   └── shared/
│       ├── config.py
│       └── utils.py
│
├── tests/
│   ├── test_preprocess.py
│   └── test_query.py
│
├── docker-compose.yml
├── README.md
└── requirements.txt
```

## Описание структуры проекта.

### `data/` - Содержит данные проекта.

- `data.json`: Файл с данными в формате JSON.
- `data.log`: Лог-файл.
- `faiss_index.bin`: Индекс для FAISS.
- `metadata.pkl`: Файл с метаданными в формате Pickle.

### `src/` - Исходный код проекта.

#### `indexing_service/` - Служба индексации.

- `Dockerfile`: Файл для сборки Docker-образа.
- `main.py`: Главный файл службы индексации.
- `analysis.py`: Модуль для анализа данных.
- `load_and_save.py`: Модуль для загрузки и сохранения данных.
- `processing.py`: Модуль для обработки данных.
- `vectorize.py`: Модуль для векторизации данных.
- `requirements.txt`: Зависимости для службы индексации.

#### `query_service/` - Служба запросов.

- `Dockerfile`: Файл для сборки Docker-образа.
- `main.py`: Главный файл службы запросов.
- `query.py`: Модуль для обработки запросов.
- `requirements.txt`: Зависимости для службы запросов.

#### `shared/` - Общие модули, используемые в проекте.

- `config.py`: Конфигурационный файл.
- `utils.py`: Утилиты и вспомогательные функции.

### `tests/` - Тесты для проекта.

- `test_preprocess.py`: Тесты для предварительной обработки.
- `test_query.py`: Тесты для службы запросов.

### Корневые файлы

- `docker-compose.yml`: Файл конфигурации для Docker Compose.
- `README.md`: Документация проекта.
- `requirements.txt`: Общие зависимости проекта.

## Описание реализованных служб

### Служба индексации

Служба индексации позволяет принимать URL-адрес с данными и возвращает индексы FAISS и метаданные индексов. В процессе преобразования данных выполняются следующие шаги:

- **Анализ данных**: Проведение базового анализа данных для понимания их структуры и содержания.
- **Очистка текста**: Удаление лишних символов и пробелов для улучшения качества данных.
- **Фильтрация строк**: Фильтрация строк на основе длины текста для удаления слишком коротких или нерелевантных записей.
- **Удаление дубликатов**: Проверка и удаление дублирующихся записей для обеспечения уникальности данных.
- **Группировка текста**: Группировка текста по `ru_wiki_pageid` для организации данных.
- **Разбивка текста**: Разбивка текста на части с учетом ограничения максимальной длины чанка для удобства обработки.
- **Проверка и исправление UTF-8**: Проверка и исправление валидности кодировки UTF-8 для обеспечения корректного отображения текста.
- **Исправление символов замены**: Проверка и исправление символов замены для улучшения читаемости текста.
- **Удаление непечатаемых символов**: Проверка и удаление непечатаемых символов для очистки данных.
- **Векторизация текстов**: Преобразование текстов в векторные представления с использованием модели SentenceTransformer.
- **Создание индекса FAISS**: Построение индекса FAISS из полученных эмбеддингов для эффективного поиска и сравнения векторов.
- **Сохранение индекса FAISS и метаданных**: Сохранение созданного индекса FAISS и связанных с ним метаданных для последующего использования.


Весь процесс преобразования сопровождается логированием для отслеживания и анализа выполненных операций.

### Служба запросов

Служба запросов принимает вопрос в формате JSON и на основе индексов FAISS и метаданных индексов возвращает ответ на вопрос в формате JSON. В процессе обработки запроса выполняются следующие шаги:

- **Загрузка метаданных и индексов**: Загрузка метаданных и индексов из файлов для дальнейшей обработки.
- **Преобразование запроса в эмбеддинг**: Преобразование запроса в эмбеддинг и нахождение заданного числа ближайших индексов для определения релевантных данных.
- **Преобразование индексов в текстовые данные**: Преобразование найденных индексов в текстовые данные из метаданных для получения контекста.
- **Формирование промпта**: Формирование промпта в формате вопрос и контекст для передачи в языковую модель.
- **Получение ответа от модели**: Получение ответа от модели Llama 3.2 3B и возвращение его в формате JSON.

Весь процесс обработки запроса сопровождается логированием для отслеживания и анализа выполненных операций.

## План дальнейших действий

### 1. Расширение службы индексации через Streamlit

Планируется расширить функциональность службы индексации, создав приложение на основе Streamlit, которое позволит:

- **Загружать базы данных**: Возможность загрузки различных баз данных для анализа и обработки.
- **Анализировать базы данных**: Проведение анализа загруженных данных для понимания их структуры и содержания.
- **Приводить базы в порядок**: Очистка и предобработка данных для улучшения их качества и удобства использования.
- **Анализировать новые базы**: Поддержка анализа новых поступающих данных для их интеграции в существующую систему.
- **Выбирать вид LLM**: Возможность выбора между использованием LLM через API или локально.
- **Выбирать конкретные LLM**: В зависимости от выбранного вида, возможность выбора конкретных моделей LLM для использования.
- **Функционал ввода вопроса и вывода ответа**: Интерактивный интерфейс для ввода вопросов и получения ответов от выбранной модели LLM.

### 2. Использование брокера для оптимизации процессов

Планируется интеграция брокера сообщений для оптимизации процессов обмена данными и управления задачами:

- **Оптимизация обмена сообщениями**: Использование брокера для эффективного управления потоками данных между различными компонентами системы.
- **Улучшение масштабируемости**: Повышение масштабируемости системы за счет распределения задач и балансировки нагрузки.
- **Надежность и отказоустойчивость**: Обеспечение надежной доставки сообщений и обработки задач даже в случае сбоев.

### 3. Проведение юнит-тестов существующих функций

Планируется проведение юнит-тестов для существующих функций с целью обеспечения их корректной работы и выявления возможных ошибок:

- **Написание тестов**: Создание тестов для всех ключевых функций и модулей.
- **Покрытие кода**: Обеспечение высокого уровня покрытия кода тестами для повышения надежности системы.
- **Автоматизация тестирования**: Интеграция тестов в процесс непрерывной интеграции и доставки (CI/CD) для автоматического выполнения тестов при каждом изменении кода.

### 4. Упаковка через Docker Compose

Планируется упаковка приложения и всех его компонентов с использованием Docker Compose для упрощения развертывания и управления:

- **Создание Docker-образов**: Создание Docker-образов для всех компонентов системы, включая службы индексации и запросов, а также брокер сообщений.
- **Настройка Docker Compose**: Создание и настройка файла `docker-compose.yml` для оркестрации и управления контейнерами.
- **Развертывание и масштабирование**: Обеспечение простого развертывания и масштабирования системы с использованием Docker Compose.


## Инструкция по установке и настройке проекта

Для использования проекта в текущем состоянии необходимо установить Docker и Ollama, а также загрузить нужную модель.

### Установка Docker

1. **Скачайте и установите Docker**:
   - Перейдите на [официальный сайт Docker](https://www.docker.com/get-started) и скачайте версию для вашей операционной системы.
   - Следуйте инструкциям по установке Docker для вашей ОС.

2. **Проверьте установку Docker**:
   - Откройте терминал или командную строку.
   - Выполните команду:
     ```bash
     docker --version
     ```
   - Убедитесь, что версия Docker отображается корректно.

### Установка и настройка Ollama

1. **Запустите контейнер Ollama**:
   - Если у вас нет видеокарты NVIDIA, выполните следующую команду:
     ```bash
     docker run -e OLLAMA_HOST=0.0.0.0:8905 -p 8905:8905 --name ollama -d ollama/ollama
     ```
   - Если у вас есть видеокарта NVIDIA и вы хотите добавить GPU в контейнер, выполните следующую команду:
     ```bash
     docker run --runtime nvidia -e OLLAMA_HOST=0.0.0.0:8905 -p 8905:8905 --name ollama -d ollama/ollama
     ```

2. **Загрузите модель в Ollama**:
   - Выполните следующую команду для загрузки модели Llama 3.2:
     ```bash
     docker exec ollama ollama pull llama3.2
     ```
   - Вы можете загрузить любую другую модель, заменив `llama3.2` на название нужной модели.

### Запуск проекта

После установки и настройки Docker и Ollama вы можете приступить к запуску проекта. Убедитесь, что все зависимости установлены и конфигурации выполнены в соответствии с документацией проекта.




